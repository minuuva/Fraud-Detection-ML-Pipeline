
---

## ğŸ›  Tech Stack

- **BigQuery** â€“ data warehousing
- **DuckDB** â€“ fast SQL-style feature engineering
- **Polars** â€“ fast dataframe transformations
- **Parquet** â€“ columnar data storage
- **XGBoost** â€“ robust gradient boosting model
- **scikit-learn** â€“ pipeline, train/test split, evaluation
- **Jupyter Notebook** â€“ training + evaluation visualization

---

## ğŸ“ˆ Evaluation Metric: AUPRC

AUPRC (Area Under the Precision-Recall Curve) is ideal for highly imbalanced datasets like fraud detection.

- A perfect model has **AUPRC = 1.0**
- A random model has **AUPRC â‰ˆ 0.01** (because only ~1% are fraud)

> ğŸ¯ This model scored **0.917** â€” indicating high precision and recall even on rare fraud cases!

---

## ğŸš€ How to Run

1. Set up your environment:
    ```bash
    pip install -r requirements.txt
    ```

2. Pull data from BigQuery:
    ```bash
    python src/data/pull_bigquery.py
    ```

3. Build features:
    ```bash
    python src/data/build_features.py
    ```

4. Train model inside Jupyter:
    ```bash
    jupyter notebook notebooks/01_train_xgb.ipynb
    ```

---

## ğŸ”’ Notes

- `bqgrid.json` (credentials) is excluded for security reasons.
- The dataset is fully synthetic.

---

## ğŸ¤ Contributing

Pull requests and suggestions are welcome!
