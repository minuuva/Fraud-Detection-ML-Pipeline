# ğŸ›¡ï¸ Fraud-Detection-ML-Pipeline

## Overview  
Fraud-Detection-ML-Pipeline is an end-to-end machine learning pipeline for detecting fraudulent transactions using a synthetic banking dataset.

The pipeline:
- ğŸ“¥ Pulls transactional data directly from BigQuery
- ğŸ§ª Engineers both row-level and account-level features with Polars and DuckDB
- ğŸ¤– Trains a highly-performant XGBoost classifier
- ğŸ“ˆ Evaluates the model using AUPRC with impressive results

âœ… **Achieved AUPRC: 0.917** â€” meaning the model is highly effective at identifying fraud in an imbalanced dataset. A random classifier would have ~0.01 AUPRC due to only 1% fraud.

---

## âœ¨ Features

- ğŸ§¹ Data extraction from BigQuery to Parquet using `pull_bigquery.py`
- ğŸ—ï¸ Feature engineering with Polars + DuckDB in `build_features.py`
- ğŸ”¢ One-hot encoding of categorical columns using `ColumnTransformer`
- âš–ï¸ Class imbalance handling via `scale_pos_weight`
- ğŸ¤– XGBoost model training and pipeline encapsulation
- ğŸ“Š AUPRC scoring to reflect fraud detection accuracy
- ğŸ’¾ Saved model as `models/fraud_xgb.json`
- ğŸ“ Organized, GitHub-ready project structure with reproducible SQL EDA

---

## ğŸ“‚ Project Structure
fraud-detection-ml-pipeline/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ features_raw.parquet
â”‚ â”œâ”€â”€ features_eng.parquet
â”‚ â””â”€â”€ bank_transactions.csv
â”œâ”€â”€ models/
â”‚ â””â”€â”€ fraud_xgb.json
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ 01_train_xgb.ipynb
â”œâ”€â”€ sql/
â”‚ â””â”€â”€ [saved EDA queries].sql
â”œâ”€â”€ src/
â”‚ â””â”€â”€ data/
â”‚ â”œâ”€â”€ build_features.py
â”‚ â””â”€â”€ pull_bigquery.py
â”œâ”€â”€ bqgrid.json # (credentials excluded from repo)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸ›  Tech Stack

- **BigQuery** â€“ data warehousing
- **DuckDB** â€“ fast SQL-style feature engineering
- **Polars** â€“ fast dataframe transformations
- **Parquet** â€“ columnar data storage
- **XGBoost** â€“ robust gradient boosting model
- **scikit-learn** â€“ pipeline, train/test split, evaluation
- **Jupyter Notebook** â€“ training + evaluation visualization

---

## ğŸ“ˆ Evaluation Metric: AUPRC

AUPRC (Area Under the Precision-Recall Curve) is ideal for highly imbalanced datasets like fraud detection.

- A perfect model has **AUPRC = 1.0**
- A random model has **AUPRC â‰ˆ 0.01** (because only ~1% are fraud)

> ğŸ¯ This model scored **0.917** â€” indicating high precision and recall even on rare fraud cases!

---

## ğŸš€ How to Run

1. Set up your environment:
    ```bash
    pip install -r requirements.txt
    ```

2. Pull data from BigQuery:
    ```bash
    python src/data/pull_bigquery.py
    ```

3. Build features:
    ```bash
    python src/data/build_features.py
    ```

4. Train model inside Jupyter:
    ```bash
    jupyter notebook notebooks/01_train_xgb.ipynb
    ```

---

## ğŸ”’ Notes

- `bqgrid.json` (credentials) is excluded for security reasons.
- The dataset is fully synthetic.

---

## ğŸ¤ Contributing

Pull requests and suggestions are welcome!
